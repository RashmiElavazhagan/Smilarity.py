# -*- coding: utf-8 -*-
"""roc_curve.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AaaSfywViEiCxEJ6SWSQ6ltXJMyLeBkW
"""

# -------------------------------------------------------------------------
# AUTHOR: Rashmi Elavazhagan
# FILENAME: roc_curve.py
# SPECIFICATION: This program trains a decision tree model on data and then plots the ROC curve.
# FOR: CS 5990 (Advanced Data Mining) - Assignment #2
# TIME SPENT: 3 hours.
# -----------------------------------------------------------*/

#importing necessary Python libraries
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from matplotlib import pyplot
import numpy as np
import pandas as pd

# read the dataset cheat_data.csv and prepare the data_training numpy array
df = pd.read_csv('cheat_data.csv', sep=',', header=0)  # reading a dataset eliminating the header (Pandas library)
data = np.array(df.values)

# transform the original training features to numbers and add them to the 5D array X.
X = []
for record in data:
    record_array = [1 if record[0] == 'Yes' else 0, 1 if record[1] == 'Single' else 0,
                    1 if record[1] == 'Married' else 0, float(str(record[2]).replace('k', ''))]
    X.append(record_array)

# transform the original training classes to numbers and add them to the vector y.
y = []
for record in data:
    y.append(1 if record[3] == 'Yes' else 0)

# split into train/test sets using 30% for test
train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3)

# generate a no skill prediction (random classifier - scores should be all zero)
ns_probs = [0] * len(test_y)

# fit a decision tree model using entropy with max depth = 2
clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=2)
clf.fit(train_X, train_y)

# predict probabilities for all test samples (scores)
dt_probs = clf.predict_proba(test_X)

# keep probabilities for the positive outcome only
dt_probs = dt_probs[:, 1]

# calculate scores by using both classifiers (no skill and decision tree)
ns_auc = roc_auc_score(test_y, ns_probs)
dt_auc = roc_auc_score(test_y, dt_probs)

# summarize scores
print('No Skill: ROC AUC=%.3f' % ns_auc)
print('Decision Tree: ROC AUC=%.3f' % dt_auc)

# calculate roc curves
ns_fpr, ns_tpr, _ = roc_curve(test_y, ns_probs)
dt_fpr, dt_tpr, _ = roc_curve(test_y, dt_probs)

# plot the roc curve for the model
pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
pyplot.plot(dt_fpr, dt_tpr, marker='.', label='Decision Tree')

# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')

# show the legend
pyplot.legend()

# show the plot
pyplot.show()